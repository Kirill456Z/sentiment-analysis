{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90926123",
   "metadata": {},
   "source": [
    "Для обучения используется датасет комментариев из соцсетей, размеченных людьми  \n",
    "http://sentistrength.wlv.ac.uk/documentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b6e8b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T18:27:04.238804Z",
     "start_time": "2022-03-29T18:27:04.182088Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/human_classified_sn.csv\", usecols=['text','target'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8cb59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T18:26:18.919068Z",
     "start_time": "2022-03-29T18:26:18.909575Z"
    }
   },
   "source": [
    "Датасет с коментариями на русском языке   \n",
    "http://study.mokoron.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fe79da5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T18:21:25.479676Z",
     "start_time": "2022-03-29T18:21:24.650270Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = pd.read_csv(\"datasets/positive.csv\", sep=\";\", usecols=['ttext','ttype'])\n",
    "neg = pd.read_csv(\"datasets/negative.csv\", sep=\";\", usecols=['ttext','ttype'])\n",
    "\n",
    "df = pd.concat([pos,neg])\n",
    "df.columns = ['text', 'target']\n",
    "df['target'] = np.where(df.target == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fd5de1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T18:21:30.760329Z",
     "start_time": "2022-03-29T18:21:26.703678Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
    "    text = re.sub('@[^\\s]+', 'USER', text)\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df['text'] = [preprocess_text(t) for t in df.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c7182",
   "metadata": {},
   "source": [
    "Дальнейший анализ можно проводить для обоих датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "556eca3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T18:27:09.008571Z",
     "start_time": "2022-03-29T18:27:08.967868Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validation = train_test_split(df, train_size = 0.8)\n",
    "X_train, Y_train = train.text, train.target\n",
    "X_validation, Y_validation = validation.text, validation.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bcdb05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T17:01:02.534642Z",
     "start_time": "2022-03-29T17:01:02.526727Z"
    }
   },
   "source": [
    "На обучающей выборке с помощбю кросс-валидации подберем пару преобразователь-модель, дающую лучшее качество auc_roc (данная метрика не зависит от выбора разделяющей границы, что может быть полезно в случае не сбалансированных классов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0c6ebf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T18:27:32.220120Z",
     "start_time": "2022-03-29T18:27:09.794274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(count + logistic) score is 0.8142632809336648\n",
      "(count + svm) score is 0.7923563823274714\n",
      "(count + knn) score is 0.7056785759275633\n",
      "(tfidf + logistic) score is 0.8285221016907037\n",
      "(tfidf + svm) score is 0.820019152626734\n",
      "(tfidf + knn) score is 0.7517912282217489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vectorizers = {\"count\" : CountVectorizer(), \"tfidf\" : TfidfVectorizer()}\n",
    "models = {\"logistic\" : LogisticRegression(max_iter = 10000), \"svm\" : LinearSVC(max_iter=10000),'knn' : KNeighborsClassifier(metric='cosine') }\n",
    "\n",
    "for vect_name, vect in vectorizers.items():\n",
    "    for model_name, model in models.items():\n",
    "        pipe = Pipeline([('vectorizer', vect), ('model', model)])\n",
    "        cv_score = cross_val_score(pipe, X_train, Y_train, scoring='roc_auc')\n",
    "        print(\"({} + {}) score is {}\".format(vect_name, model_name, cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a759d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T17:04:17.035071Z",
     "start_time": "2022-03-29T17:04:17.027956Z"
    }
   },
   "source": [
    "Лучшее качество дает TfIdf векторизатор и логистическая регрессия. Дальше будем подбирать гиперпараметры. Подберем коэффициент регуляризации для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e37cc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T18:27:16.765Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "cv_selection = Pipeline([('vectorizer', TfidfVectorizer()), ('model', LogisticRegressionCV(max_iter = 1000, scoring='roc_auc'))])\n",
    "cv_selection.fit(X_train, Y_train)\n",
    "model = cv_selection.named_steps['model']\n",
    "best_C = model.C_[0]\n",
    "best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723dbff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T17:04:48.343890Z",
     "start_time": "2022-03-29T17:04:48.337776Z"
    }
   },
   "source": [
    "Посчитаем качество на валидации для оптимального C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9b74f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T18:27:17.328Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pipe = Pipeline([('vectorizer', TfidfVectorizer()), ('model', LogisticRegression(max_iter = 10000, C=best_C))])\n",
    "pipe.fit(X_train, Y_train)\n",
    "print(roc_auc_score(Y_validation, pipe.predict_proba(X_validation)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb34b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T17:06:03.997194Z",
     "start_time": "2022-03-29T17:06:03.993013Z"
    }
   },
   "source": [
    "Теперь по валидационной выборке будем подбирать преобразования текста.\n",
    "Попробуем удалить из текста стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7b8e8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T18:27:17.684Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "pipe = Pipeline([('vectorizer', TfidfVectorizer(stop_words = stopwords.words(\"english\"))), ('model', LogisticRegression(max_iter = 10000, C=best_C))])\n",
    "pipe.fit(X_train, Y_train)\n",
    "print(roc_auc_score(Y_validation, pipe.predict_proba(X_validation)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353e957",
   "metadata": {},
   "source": [
    "Попробуем приводить слова к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7403a3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T18:27:18.057Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem(data):\n",
    "    return data.apply(lambda x : stemmer.stem(x))\n",
    "\n",
    "pipe = Pipeline([('vectorizer', TfidfVectorizer()), ('model', LogisticRegression(max_iter = 10000, C=best_C))])\n",
    "pipe.fit(stem(X_train), Y_train)\n",
    "print(roc_auc_score(Y_validation, pipe.predict_proba(stem(X_validation))[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e757000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T17:18:03.680443Z",
     "start_time": "2022-03-29T17:18:03.666683Z"
    }
   },
   "source": [
    "Попробуем рассматривать в качестве признаков также наборы слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e312ff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T18:27:18.541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pipe = Pipeline([('vectorizer', TfidfVectorizer(ngram_range=(1,2))), ('model', LogisticRegression(max_iter = 10000, C=best_C))])\n",
    "pipe.fit(X_train, Y_train)\n",
    "print(roc_auc_score(Y_validation, pipe.predict_proba(X_validation)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2539a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T17:19:24.816321Z",
     "start_time": "2022-03-29T17:19:24.810008Z"
    }
   },
   "source": [
    "В итоге лучшее качество на валидации дает рассматривание слов и словосочетаний исходных текстов (без \n",
    "лемматизации и удаления стоп-слов)\n",
    "Посмотрим на зависимость точности от границы разделения классов и выберем оптимальную границу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0e1bf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T18:27:19.691Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe = Pipeline([('vectorizer', TfidfVectorizer(ngram_range=(1,2))), ('model', LogisticRegression(C=best_C, max_iter = 10000))])\n",
    "pipe.fit(X_train, Y_train)\n",
    "validate_prediction = pipe.predict_proba(X_validation)\n",
    "precision, recall, thresh = precision_recall_curve(Y_validation, validate_prediction[:,1])\n",
    "acc = np.array([accuracy_score(Y_validation, np.where(validate_prediction[:,0] > tr, 0, 1)) for tr in thresh])\n",
    "best_threshold = thresh[acc.argmax()]\n",
    "sns.lineplot(x=thresh, y=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72100b2b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-29T18:27:20.706Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.best_threshold = best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed344e5",
   "metadata": {},
   "source": [
    "Сохраняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fc064c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T18:24:10.387281Z",
     "start_time": "2022-03-29T18:24:09.758245Z"
    }
   },
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "with open(\"model.pkl\", 'wb') as file:\n",
    "    dump(pipe, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:introduction_to_da] *",
   "language": "python",
   "name": "conda-env-introduction_to_da-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
